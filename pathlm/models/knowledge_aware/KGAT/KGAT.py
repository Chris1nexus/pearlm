'''
Created on Dec 03, 2023
Pytorch Implementation of Knowledge Graph Attention Network (KGAT) model in:
Wang Xiang et al. KGAT: Knowledge Graph Attention Network for Recommendation. In KDD 2019.
@author: Xiang Wang (xiangwang@u.nus.edu)
'''
from typing import Tuple, Callable, Dict, Union

import numpy as np
import scipy.sparse as sp
import torch
import torch.nn.functional as F
from torch import nn, optim


class KGAT(nn.Module):
    def __init__(self, data_config, pretrain_data, args):
        super(KGAT, self).__init__()
        self._parse_args(data_config, pretrain_data, args)
        self.device = args.device
        self._build_weights()
        # Setting the aggregation function based on the alg_type
        method_mapper = {
            "bi": self.create_bi_interaction_embed,
            "kgat": self.create_bi_interaction_embed,
            #"gcn": self._gcn_method,
            #"graphsage": self._graphsage_method
        }

        if self.alg_type in method_mapper:
            self.aggregation_fun = lambda: method_mapper[self.alg_type]
        else:
            raise NotImplementedError
        # Define the two sets of parameters for each optimizer
        # Correctly gather parameters for the recommendation optimizer
        rec_params = []
        rec_params.extend(self.user_embed.parameters())
        rec_params.extend(self.entity_embed.parameters())
        #rec_params.extend(self.gc_layers.parameters())
        #rec_params.extend(self.bi_layers.parameters())
        #rec_params.extend(self.mlp_layers.parameters())
        # Include other parameters related to 'rec' if necessary

        # Correctly gather parameters for the KGE optimizer
        kge_params = []
        kge_params.extend(self.relation_embed.parameters())
        kge_params.append(self.trans_W)

        # Initialize the two optimizers
        self.recommendation_opt = torch.optim.Adam(self.parameters(), lr=self.lr)
        self.kge_opt = torch.optim.Adam(self.parameters(), lr=args.lr)
        self._statistics_params()

    def _define_layer(self, in_size, out_size, name):
        setattr(self, f'W_{name}', nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty(in_size, out_size))))
        setattr(self, f'b_{name}', nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty(1, out_size))))

    def _build_weights(self):
        if self.pretrain_data is None:
            self.user_embed = torch.nn.Embedding(self.n_users, self.emb_dim).to(self.device)
            self.entity_embed = torch.nn.Embedding(self.n_entities, self.emb_dim).to(self.device)
            torch.nn.init.xavier_uniform_(self.user_embed.weight.data)
            torch.nn.init.xavier_uniform_(self.entity_embed.weight.data)
            print('using xavier initialization, for user and entity embed')
        else:
            self.user_embed = nn.Parameter(
                torch.tensor(self.pretrain_data['user_embed'], dtype=torch.float32)).to(self.device)

            item_embed = torch.tensor(self.pretrain_data['item_embed'], dtype=torch.float32).to(self.device)
            other_embed = torch.nn.init.xavier_uniform_(torch.empty(self.n_entities - self.n_items, self.emb_dim)).to(self.device)

            self.entity_embed = nn.Parameter(torch.cat([item_embed, other_embed], dim=0)).to(self.device)
            print('using pretrained initialization')

        #self.relation_embed = nn.Parameter(
        #    torch.nn.init.xavier_uniform_(torch.empty(self.n_relations, self.kge_dim)))
        self.relation_embed = torch.nn.Embedding(self.n_relations, self.kge_dim).to(self.device)
        torch.nn.init.xavier_uniform_(self.relation_embed.weight.data)

        self.trans_W = nn.Parameter(torch.empty(self.n_relations, self.emb_dim, self.kge_dim))
        nn.init.xavier_uniform_(self.trans_W)
        #self.trans_W = nn.Embedding(self.n_relations, self.emb_dim * self.kge_dim)
        #nn.init.xavier_uniform_(self.trans_W.weight)

        self.weight_size_list = [self.emb_dim] + self.weight_size

        self.gc_layers, self.bi_layers, self.mlp_layers = nn.ModuleList(), nn.ModuleList(), nn.ModuleList()
        for k in range(self.n_layers):
            # Graph Convolutional Layers
            W_gc = nn.Parameter(
                torch.nn.init.xavier_uniform_(torch.empty(self.weight_size_list[k], self.weight_size_list[k + 1])))
            b_gc = nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty(1, self.weight_size_list[k + 1])))
            self.gc_layers.append(nn.Linear(self.weight_size_list[k], self.weight_size_list[k + 1]))
            self.register_parameter(f'W_gc_{k}', W_gc)
            self.register_parameter(f'b_gc_{k}', b_gc)

            # Bilinear Layers
            W_bi = nn.Parameter(
                torch.nn.init.xavier_uniform_(torch.empty(self.weight_size_list[k], self.weight_size_list[k + 1])))
            b_bi = nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty(1, self.weight_size_list[k + 1])))
            self.bi_layers.append(nn.Linear(self.weight_size_list[k], self.weight_size_list[k + 1]))
            self.register_parameter(f'W_bi_{k}', W_bi)
            self.register_parameter(f'b_bi_{k}', b_bi)

            # MLP Layers
            W_mlp = nn.Parameter(
                torch.nn.init.xavier_uniform_(torch.empty(2 * self.weight_size_list[k], self.weight_size_list[k + 1])))
            b_mlp = nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty(1, self.weight_size_list[k + 1])))
            self.mlp_layers.append(nn.Linear(2 * self.weight_size_list[k], self.weight_size_list[k + 1]))
            self.register_parameter(f'W_mlp_{k}', W_mlp)
            self.register_parameter(f'b_mlp_{k}', b_mlp)
        self.A_values = torch.FloatTensor(len(self.all_h_list)).to(self.device)


    def _initialize_tensor(self, value: float = 0.0) -> torch.Tensor:
        """Initialize a tensor with the given value."""
        return torch.tensor(value).float().to(self.device)

    def train_step(self, batch_data, mode: str) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        Execute one training step based on the given mode ('rec' or 'kge').

        Args:
            batch_data: Data required for the training step.
            mode (str): Specifies the mode of operation, either 'rec' for recommendation or 'kge' for knowledge graph embedding.

        Returns:
            Tuple of batch loss, base loss, kge loss, and regularization loss.
        """
        base_loss = self._initialize_tensor()
        kge_loss = self._initialize_tensor()
        reg_loss = self._initialize_tensor()
        batch_loss = self._initialize_tensor()

        if mode == 'rec':
            u_e, pos_i_e, neg_i_e = self.forward(batch_data, mode)
            base_loss, reg_loss, recommendation_loss = self._bpr_loss(u_e, pos_i_e, neg_i_e)
            batch_loss = recommendation_loss
            opt = self.recommendation_opt

        elif mode == 'kge':
            h_e, r_e, pos_t_e, neg_t_e = self.forward(batch_data, mode)
            kge_loss, reg_loss = self._kge_loss(h_e, r_e, pos_t_e, neg_t_e)
            batch_loss = kge_loss
            opt = self.kge_opt
        else:
            raise ValueError("Invalid mode")

        opt.zero_grad()
        batch_loss.backward()
        opt.step()

        return batch_loss, base_loss, kge_loss, reg_loss

    def forward(self, batch_data: Dict[str, torch.Tensor], mode: str) -> Union[torch.Tensor, None]:
        """
        Forward pass based on the given mode.

        Args:
            batch_data: Data required for the forward pass.
            mode (str): Specifies the mode of operation.

        Returns:
            Result of the forward pass or None.
        """
        if mode == 'rec':
            #users, pos_items, neg_items = batch_data
            return self._forward_phase_I(batch_data['users'], batch_data['pos_items'], batch_data['neg_items'])
        elif mode == 'kge':
            heads, relations, pos_tails, neg_tails = [torch.IntTensor(x).to(self.device) for x in batch_data]
            return self._forward_phase_II(heads, relations, pos_tails, neg_tails)
        elif mode == 'eval':
            u_e, pos_i_e, _ = self._forward_phase_I(batch_data['users'], batch_data['pos_items'])
            return torch.matmul(u_e, pos_i_e.t())  # Transpose pos_i_e for matrix multiplication

        else:
            raise ValueError("Invalid mode")

    """
    *********************************************************
    Compute Graph-based Representations of All Users & Items & KG Entities via Message-Passing Mechanism of Graph Neural Networks.
    Different Convolutional Layers:
        1. bi: defined in 'KGAT: Knowledge Graph Attention Network for Recommendation', KDD2019;
        2. gcn:  defined in 'Semi-Supervised Classification with Graph Convolutional Networks', ICLR2018;
        3. graphsage: defined in 'Inductive Representation Learning on Large Graphs', NeurIPS2017.
    """
    def _forward_phase_I(self, users, pos_items, neg_items=None):
        ua_embeddings, ea_embeddings = self.create_bi_interaction_embed()
        u_e, pos_i_e, neg_i_e = ua_embeddings[users], ea_embeddings[pos_items], ea_embeddings[neg_items]
        return u_e, pos_i_e, neg_i_e
    """
    *********************************************************
    Compute Knowledge Graph Embeddings via TransR.
    """

    def _forward_phase_II(self, h, r, pos_t, neg_t):
        h_e, r_e, pos_t_e, neg_t_e = self._get_kg_inference(h, r, pos_t, neg_t)
        self.A_kg_score = self._generate_transE_score(h=h, t=pos_t, r=r)
        self.A_out = self._create_attentive_A_out()
        return h_e, r_e, pos_t_e, neg_t_e

    def _get_kg_inference(self, h, r, pos_t, neg_t):
        """
                Retrieve the knowledge graph embeddings for given entities and relations.

                Given tensors of head entities (h), relations (r), positive tail entities (pos_t),
                and negative tail entities (neg_t), this function returns their respective embeddings.

                Args:
                    h (torch.Tensor): Tensor of head entities.
                    r (torch.Tensor): Tensor of relations.
                    pos_t (torch.Tensor): Tensor of positive tail entities.
                    neg_t (torch.Tensor): Tensor of negative tail entities.

                Returns:
                    Tuple[torch.Tensor, ...]: A tuple containing transformed embeddings for head entities,
                                              relation embeddings, positive tail entities, and negative tail entities.
                """
        embeddings = torch.cat([self.user_embed.weight, self.entity_embed.weight], dim=0)
        embeddings = embeddings.unsqueeze(1)

        # Embedding lookup for head & tail entities
        h_e = embeddings[h]
        pos_t_e = embeddings[pos_t]
        neg_t_e = embeddings[neg_t]

        # Relation embeddings
        r_e = self.relation_embed(r)

        # Relation transform weights
        trans_M = self.trans_W[r]

        # Perform matrix multiplication and reshape
        h_e = torch.matmul(h_e, trans_M).view(-1, self.kge_dim)
        pos_t_e = torch.matmul(pos_t_e, trans_M).view(-1, self.kge_dim)
        neg_t_e = torch.matmul(neg_t_e, trans_M).view(-1, self.kge_dim)

        # L2 normalization can be added here if needed

        return h_e, r_e, pos_t_e, neg_t_e


    """
    Optimize Recommendation (CF) Part via BPR Loss.
    """

    def _bpr_loss(self, u_e, pos_i_e, neg_i_e):
        pos_scores = torch.sum(u_e * pos_i_e, dim=1)
        neg_scores = torch.sum(u_e * neg_i_e, dim=1)
        bpr_loss = F.softplus(-(pos_scores - neg_scores)).mean()

        # Regularization
        reg_loss = (u_e.norm(p=2).pow(2) +
                    pos_i_e.norm(p=2).pow(2) +
                    neg_i_e.norm(p=2).pow(2))
        reg_loss = (reg_loss / self.batch_size) * self.regs[0]

        loss = bpr_loss + reg_loss
        return bpr_loss, reg_loss, loss

    def _kge_loss(self, h_e, r_e, pos_t_e, neg_t_e):
        pos_kg_score = torch.sum((h_e + r_e - pos_t_e).pow(2), dim=1, keepdim=True)
        neg_kg_score = torch.sum((h_e + r_e - neg_t_e).pow(2), dim=1, keepdim=True)
        # Using the softplus as BPR loss to avoid the nan error.
        kg_loss = F.softplus(-(neg_kg_score - pos_kg_score)).mean()
        kg_reg_loss = h_e.norm(p=2).pow(2) + r_e.norm(p=2).pow(2) + \
                      pos_t_e.norm(p=2).pow(2) + neg_t_e.norm(p=2).pow(2)
        kg_reg_loss = kg_reg_loss / self.batch_size_kg
        reg_loss = self.regs[1] * kg_reg_loss
        kge_loss = kg_loss + reg_loss
        return kge_loss, reg_loss

    def _split_A_hat(self, X):
        A_fold_hat = []

        fold_len = (self.n_users + self.n_entities) // self.n_fold

        for i_fold in range(self.n_fold):
            start = i_fold * fold_len
            if i_fold == self.n_fold - 1:
                end = self.n_users + self.n_entities
            else:
                end = (i_fold + 1) * fold_len

            A_fold_hat.append(self._convert_sp_mat_to_sp_tensor(X[start:end]))
        return A_fold_hat

    def _convert_sp_mat_to_sp_tensor(self, X):
        coo = X.tocoo().astype(np.float32)
        indices = torch.LongTensor(np.vstack((coo.row, coo.col)))
        values = torch.FloatTensor(coo.data)
        return torch.sparse_coo_tensor(indices, values, coo.shape)

    def _create_attentive_A_out(self):
        indices = torch.LongTensor(np.vstack([self.all_h_list, self.all_t_list]).transpose()).to(self.device)
        A = torch.sparse.softmax(torch.sparse_coo_tensor(indices.t(), self.A_values, self.A_in.shape), dim=1)
        return A


    def update_attentive_A(self):
        """
        Update the adjacency matrix A using attentive TransE scores.

        This function computes the attentive adjacency matrix by splitting the data into
        batches, computing the TransE scores for each batch, and then constructing a new
        adjacency matrix using the scores.
        """
        fold_len = len(self.all_h_list) // self.n_fold
        kg_scores = []

        for i_fold in range(self.n_fold):
            start = i_fold * fold_len
            end = len(self.all_h_list) if i_fold == self.n_fold - 1 else (i_fold + 1) * fold_len

            h_batch = torch.tensor(self.all_h_list[start:end], dtype=torch.long).to(self.device)
            r_batch = torch.tensor(self.all_r_list[start:end], dtype=torch.long).to(self.device)
            pos_t_batch = torch.tensor(self.all_t_list[start:end], dtype=torch.long).to(self.device)

            A_kg_score = self._generate_transE_score(h_batch, pos_t_batch, r_batch)
            kg_scores.append(A_kg_score.detach().cpu().numpy())

        kg_scores = np.concatenate(kg_scores)

        # Create the attentive adjacency matrix
        indices = np.vstack([self.all_h_list, self.all_t_list]).transpose()
        A_in_coo = sp.coo_matrix((kg_scores, (indices[:, 0], indices[:, 1])),
                                 shape=(self.n_users + self.n_entities, self.n_users + self.n_entities))
        self.A_in = A_in_coo.tocsr()

        if self.alg_type in ['org', 'gcn']:
            # Adding diagonal elements
            self.A_in.setdiag(np.ones(self.n_users + self.n_entities))

    def _generate_transE_score(self, h: torch.Tensor, t: torch.Tensor, r: torch.Tensor) -> torch.Tensor:
        # Concatenate user and entity embeddings
        embeddings = torch.cat([self.user_embed.weight, self.entity_embed.weight], dim=0)
        embeddings = embeddings.unsqueeze(1)

        # Embedding lookup for head and tail entities
        h_e = embeddings[h]
        t_e = embeddings[t]

        # Relation embeddings
        r_e = self.relation_embed(r)

        # Relation transform weights
        trans_M = self.trans_W[r]

        # Perform matrix multiplication and reshape
        h_e = torch.matmul(h_e, trans_M).view(-1, self.kge_dim)
        t_e = torch.matmul(t_e, trans_M).view(-1, self.kge_dim)

        # L2 normalization can be added here if needed

        # Calculate TransE score
        kg_score = torch.sum(t_e * torch.tanh(h_e + r_e), dim=1)

        return kg_score

    def _statistics_params(self):
        # number of params
        total_parameters = sum(p.numel() for p in self.parameters())
        if self.verbose > 0:
            print("#params: %d" % total_parameters)

    def create_bi_interaction_embed(self):
        # Generate a set of adjacency sub-matrix.
        A_fold_hat = self._split_A_hat(self.A_in)

        ego_embeddings = torch.cat([self.user_embed.weight, self.entity_embed.weight], dim=0)
        all_embeddings = [ego_embeddings]

        for k in range(self.n_layers):
            temp_embed = [torch.sparse.mm(A_fold.to(self.device), ego_embeddings) for A_fold in A_fold_hat]

            # Sum messages of neighbors.
            side_embeddings = torch.cat(temp_embed, 0)

            add_embeddings = ego_embeddings + side_embeddings

            # Transformed sum messages of neighbors.
            W_gc, b_gc = getattr(self, f'W_gc_{k}'), getattr(self, f'b_gc_{k}')
            sum_embeddings = F.leaky_relu(torch.mm(add_embeddings, W_gc) + b_gc)

            # Bi messages of neighbors.
            bi_embeddings = ego_embeddings * side_embeddings
            # Transformed bi messages of neighbors.
            W_bi, b_bi = getattr(self, f'W_bi_{k}'), getattr(self, f'b_bi_{k}')
            bi_embeddings = F.leaky_relu(torch.mm(bi_embeddings, W_bi) + b_bi)

            ego_embeddings = bi_embeddings + sum_embeddings

            # Message dropout.
            ego_embeddings = F.dropout(ego_embeddings, self.mess_dropout[k])

            # Normalize the distribution of embeddings.
            norm_embeddings = F.normalize(ego_embeddings, p=2, dim=1)

            all_embeddings.append(norm_embeddings)

        all_embeddings = torch.cat(all_embeddings, 1)
        ua_embeddings, ea_embeddings = torch.split(all_embeddings, [self.n_users, self.n_entities], 0)

        return ua_embeddings, ea_embeddings


    def _parse_args(self, data_config, pretrain_data, args):
        # argument settings
        self.model_type = 'kgat'
        self.device = args.device
        self.pretrain_data = pretrain_data

        self.n_users = data_config['n_users']
        self.n_items = data_config['n_items']
        self.n_entities = data_config['n_entities']
        self.n_relations = data_config['n_relations']

        self.n_fold = 100

        # initialize the attentive matrix A for phase I.
        self.A_in = data_config['A_in']

        self.all_h_list = data_config['all_h_list']
        self.all_r_list = data_config['all_r_list']
        self.all_t_list = data_config['all_t_list']
        self.all_v_list = data_config['all_v_list']

        self.adj_uni_type = args.adj_uni_type

        self.lr = args.lr

        # settings for CF part.
        self.emb_dim = args.embed_size
        self.batch_size = args.batch_size

        # settings for KG part.
        self.kge_dim = args.kge_size
        self.batch_size_kg = args.batch_size_kg

        self.weight_size = eval(args.layer_size)
        self.n_layers = len(self.weight_size)

        self.alg_type = args.alg_type
        self.model_type += '_%s_%s_%s_l%d' % (args.adj_type, args.adj_uni_type, args.alg_type, self.n_layers)
        self.mess_dropout = eval(args.mess_dropout)
        self.regs = eval(args.regs)
        self.verbose = args.verbose




